{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "## Introduction\n",
    "\n",
    "**Datalizer** is a Python package designed to simplify early-stage data analysis.\n",
    "\n",
    "Its goal is to help users:\n",
    "- Load and validate structured datasets\n",
    "- Detect and resolve common data issues (e.g. missing values, duplicates)\n",
    "- Prepare numerical data for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datalizer as dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Data\n",
    "\n",
    "The first step in any data project is to load your dataset.  \n",
    "`Datalizer` provides a convenient function called `load_data()` that reads `.csv`, `.xlsx`, or `.json` files and ensures that the dataset is entirely numerical.\n",
    "\n",
    "If non-numeric data is detected, `load_data()` will raise an error — helping you catch issues early in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>68</td>\n",
       "      <td>175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>75</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>60</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>80</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>80</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  weight  height\n",
       "0   25      68   175.0\n",
       "1   30      75   180.0\n",
       "2   22      60   165.0\n",
       "3   35      80   185.0\n",
       "4   35      80   185.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify a file path\n",
    "file_path = \"sample_numerical.csv\"\n",
    "\n",
    "# Load a sample dataset\n",
    "df = dl.load_data(file_path=file_path)\n",
    "\n",
    "# Show the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Issues\n",
    "\n",
    "Before cleaning a dataset, it's good practice to identify any existing problems.  \n",
    "The `check_for_issues()` function quickly inspects your dataset and reports:\n",
    "\n",
    "- Number of missing values\n",
    "- Number of duplicate rows\n",
    "- Displays the problematic rows, if there are any\n",
    "\n",
    "This step helps you decide what kind of cleaning strategy to apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of missing cells: 1\n",
      "\n",
      "Rows with missing values:\n",
      "   age  weight  height\n",
      "5   28      70     NaN\n",
      "\n",
      "Number of duplicate rows: 1\n",
      "\n",
      "Duplicate rows:\n",
      "   age  weight  height\n",
      "4   35      80   185.0\n"
     ]
    }
   ],
   "source": [
    "dl.check_for_issues(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Dataset\n",
    "\n",
    "Once issues are detected, you can clean the dataset using `clean_basic()`.\n",
    "\n",
    "This function:\n",
    "- Removes duplicate rows\n",
    "- Handles missing values based on a selected strategy:\n",
    "  - `\"mean\"` – fill missing values with column means\n",
    "  - `\"median\"` – fill with column medians\n",
    "  - `\"mode\"` – fill with most frequent values\n",
    "  - `\"drop\"` – remove rows with missing values entirely\n",
    "\n",
    "By default, `clean_basic()` returns a new cleaned DataFrame without modifying the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values detected. Cleaning with strategy: 'drop'.\n",
      "\n",
      "Data after cleaning:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>68</td>\n",
       "      <td>175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>75</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>60</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>80</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  weight  height\n",
       "0   25      68   175.0\n",
       "1   30      75   180.0\n",
       "2   22      60   165.0\n",
       "3   35      80   185.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dl.clean_basic(df, strategy=\"drop\")\n",
    "\n",
    "print(\"\\nData after cleaning:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Dataset\n",
    "\n",
    "### Acknowledgement\n",
    "\n",
    "The dataset used in this notebook is sourced from **\"Within-Project Defect Prediction for Ansible\"** by **Elif Ceren Gok**. It is available on **OpenML** at the following link: [OpenML Dataset](https://www.openml.org/search?type=data&status=active&id=43357).\n",
    "\n",
    "### Data Preprocessing\n",
    "Using `preprocess_data()`, we perform the following steps:\n",
    "\n",
    "- **Merging** the feature set (`X_train`) and target dataset (`y_train`) on the `id` column.\n",
    "- **Removing correlated features**: Highly correlated features are identified and removed from the dataset to reduce multicollinearity.\n",
    "- **Splitting the data**: The dataset is split into training and validation sets for model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped correlated features:\n",
      " ['additions_max', 'code_churn_max', 'num_tasks', 'delta_num_keys', 'delta_num_tasks', 'delta_num_tokens']\n"
     ]
    }
   ],
   "source": [
    "# Acknowledgement\n",
    "# The following dataset is sourced from \"Within-Project Defect Prediction for Ansible\" by user Elif Ceren Gok. https://www.openml.org/search?type=data&status=active&id=43357\n",
    "\n",
    "# File paths for the dataset\n",
    "X_file_path = \"X_train.csv\"\n",
    "y_file_path = \"y_train.csv\"\n",
    "\n",
    "# Load the data using the datalizer loader function\n",
    "X = dl.load_data(file_path=X_file_path)\n",
    "y = dl.load_data(file_path=y_file_path)\n",
    "\n",
    "# Preprocess the data\n",
    "# Merge the datasets on 'id', split into training and validation sets, remove correlated features, and return the result\n",
    "X_train_split, X_val_split, y_train_split, y_val_split, dropped_corr_feats = dl.preprocess_data(X, y, merge_col=\"id\", val=True, target_col=\"failure_prone\", remove_corr=True)\n",
    "\n",
    "# Output the dropped features due to high correlation\n",
    "print(\"Dropped correlated features:\\n\",dropped_corr_feats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scientific_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
